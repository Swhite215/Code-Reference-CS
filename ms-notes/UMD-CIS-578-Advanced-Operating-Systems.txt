Security and Privacy in Cloud Computing

1. 09/05/2024 - Summary of Lecture
    - Introduction
        - Operating System - intermediary between a user of a computer and the computer hardware
        - System Structure
            - Hardware - basic computign resources e.g. CPU, memory, I/O devices
            - Operating System
            - Application Programs - compilers, browsers, database, video games
            - Users - people, machines, other computers
            - Bottom Up - Hardware -> Operating System -> Application Programs -> Users
        - System Definition
            - Resource Allocator - manage all resources, decides between conflicting requests for efficient and fair resource use
            - Control Program - controls execution of programs to prevent errors and improper use of the computer
            - Kernel - program running at all times on the computer
                - Goal - handle core functions that are really important e.g. scheduler
        - Computer Start-Up (Multi-Step)
            - Problem - OS needs to interface with hardware it does not know about
            - Solution - Firmware, enough data to identify locations to load OS
            - Bootstrap Program - BIOS - ROM or EPROM - initialize all aspects of system
        - Organization
            - Memory
            - Bus
            - Components - CPU, Disk, USB, Graphiucs
        - Interrupt
            - Trap or Exception to generate an interrupt
            - Control transfers to the interrupt service routine through the interrupt vector, address of all service routines
            - Alternative - Polling
            - Interrupt Handling
                - Preserve state of the CPU by storing registers and program counter
                - State - values in registers, program execution point, stack, heap, program code
        - Storage Hierarchy
            - Registers (Fast, Expensive, Small)
            - Cache
            - Main Memory
            - Solid State Disk
            - Hard Disk
            - Optical Disk
            - Magnetic Tapes (Slow, Cheap, Large)
            - Access Time - .n nanoseconds to 5m nanoseconds
        - Caching
            - Storing important, frequently used data, closer to the CPU
            - If data in cache, cache hit, if not, cache miss, must load data to cache
        - Direct Memory Access
            - For certain devices, driver should talk directly to memory, improving speed of system
            - Data can be transferred in a block
            - CPU is not involved
        - How a Modern Computer Works - Von Neumann
            - Program, Data - Sequence of Bytes
            - Simplify to handle instructions
        - Processing
            - Multiprocessor Architecture - single main memory, multiple CPUs
            - Asymmetric - each processor is assigned a specific task
            - Symmetric - each processor performs all tasks
        - Multi-Programming
            - Organization of jobs so CPU always has one to execute
            - Jobs are run via job scheduling
            - A single CPU can be multi-programmed
        - Multi-Threading - single program whose tasks are split amongst multiple threads
        - Timesharing - multiple userrs on a single system, keep CPU busy
        - Modes
            - User - abstracted layer through which user's request access to computer resources
            - Kernel - privileged access to important resources and system calls
            - Transition
                - User Process -> System Call -> Trap to Kernel Mode -> Execute System Call -> Return from Trap
        - Process Management
            - Process - mental model for a program
            - Requirements - CPU, memory, I/O, files, data, program counter, registers
        - Protection and Security
            - Protection - mechanism for controlling access of processes or users to resources defined by the OS
            - Security - defense of the system against internal and external attacks
            - Users
                - User Identities - name, id, number
                - User ID assocaited with all files
                - Group Identifier - set of users to be defined and controls managed
                - Privilege Escalation - allows user to change to effective ID with more rights
        - Model of Computer Networks/Systems
            - Client/Server - client communicates with hosted servers
            - Peer to Peer - clients directly communication with each other
    - OS Structure
        - Operating System Services
            - user interface, program execution, I/O operations, file system, communications, error detection
            - resource allocation, accounting, protection and security

2. 09/12/2024
    - View of Operating System
        - Kernel - Mono vs. Micro
            - Monolithic - shared, + performance, - security
            - Micro - isolated, message passing, +security, - performance
        - Application Programming Interface
            - System Call Implementation
                - Name = Unique ID
                - Unique ID - optimized look up of call through index into an array
            - Parameter Passing
                - Registers - fast, normally only a few registers are available
                - Block Memory - store all, pass starting in a list, immediate access by memory address multiple times
                - Stack - push and pop, must push and pop to target value
            - Types of System Call
                - File Management
                - Memory Management
                - Communication
                - Parallel Programming
            - Background Services/Processes
                - Background - process started, memory allocated, put process to sleep
        - Design
            - Policy - what will be done
            - Mechanism - how will it be done
        - Layered Approach
            - Layer 0 (Hardware) -> Layer X (Kernel) -> Layer N (User)
        - Microkernel System Structure
            - Positive - separation of concerns, modularity, reduction of bugs
            - Negative - communication between microkernels,
            - Goal - essential kernel mode functionality is encapsulated as independent kernels that communication with each other
            - Other - Loadable Kernel Module
    - SMP vs. AMP
        - Multiprocessing/Multiprocessors
            - Why:
                - Limitation of a single CPU
                - Multiple Users
                - Multiple Applications
                - Multi-Tasking
                - Responsiveness and Throughput
            - Issue: how do I make use of multiple processors?
        - Symmetric Multiprocessing - all cores are treated equally
        - Asymmetric Multiprocessing - one or more cores are specialized
        - Instructions and Data Streams
            - Single Instruction Single Data - single instruction on single piece of data (traditional)
            - Multiple Instruction Multiple Data - multiple instructions for multiple pieces of data
            - Single Instruction Multiple Data - same instruction on multiple pieces of data (graphics processing)
            - Multiple Instruction Single Data - redundancy, verification
        - Processor Coupling
            - Tightly Coupled - CPUs are connected over a bus
                - + access to a shared central memory
            - Loosely Coupled - processors interconnected via a high speed communication system
                - + isolation
        - Architectures
            - Message Passing
                - - latency
                - + isolation
            - Shared Memory - multiple programs acceessing same memory
                - + low latency, easy, difficult to scale
        - Memory Access
            - Bus Based Uniform Memory Access - access time for each CORE is uniform
            - Non Uniform Based Memory Access - access time to local memory for process is faster than access to another processors's remote memory
        - Operating System Distribution
            - Option #1 - OS on all CPUs
            - Option #2 - OS on one CPU, system calls passed to Main CPU for processing
            - Option #3 - Kernel is on everything
    - Von Neumann Model
        - What - program instructions and data are both stored as sequences of bits in computer memory
        - Memory Interface
            - Memory Address Bus - memory addres for the addres bus
            - Memory Data Bus - ?
            - Address Space - amount of data that can be stored
            - Addressability - number of bits stored in each memory location
        - Processing Unit
            - Arithmetic and Logic Unit - arithmetic, boolean, logical
            - Word Length - number of bits processed by the ALU
        - Control Unit
            - What - directs execution of the program, prevent bus conflicts and timing/propogation problems
            - Program Counter - points to next instruction
            - Instruction Register - currently executing instruction
            - Status Register - last instruction executed and system parameters
        - Reduced Instruction Set Computer - one instruction per clock cycle
        - Complex Instruction Set Computer - multiple clock cycles per instruction
        - Bottleneck - all instructions and data has to be fetched from memory, path to memory is bottleneck
    - Process Continued
        - What - program in exeuction
        - Program - passive
        - Process - active
        - Parts
            - Code
            - Program Counter
            - Stack - temporary data, grows down
            - Data - global variables
            - Heap - dynamic memory, grows up
        - States - new, running, waiting, ready, terminated
        - Diagram - new -> ready, ready -> running, running -> ready, running -> waiting, running -> terminated
        - Process Control Block
            - Process State
            - Process Number
            - Program Counter
            - Registers
            - Memory Limits
            - Open Files
        - Scheduling
            - Job Queue - set of all processes in the system
            - Ready Queue - all processes residing in main memory, ready and waiting to execute
            - Device Queues - set of processes waiting for an I/O device
            - Schedulers
                - Short Term - selects which process should be executed next and allocates CPU
                - Long Term - selects which processes should be brought into ready queue, controls multiprogramming, mix of CPU and I/O
                - Mid Term - remove process from memory, store on disk, bring back in from disk i.e. swapping
            - Bounds
                - I/O Bound - spends more time doing I/O than computations, many short CPU bursts
                - CPU Bound - spends more time doing computations, very few long CPU bursts
        - Context Switch
            - Context = PCB
            - What - when CPU switches to another process, the system must save the state of the old process and load the saved data for the new process
        - Process Creation
            - Parent - initial process
            - Children - created by parent
            - Process Identifier - PID
            - Resource Sharing
                - Parent and Children share all resources
                - Children share subset of Parent's resources
                - Parent and Children share no resources
            - Execution Options
                - Parent and Children execute concurrently
                - Parent waits until Children terminate

3. 09/19/2024
    - Multitasking in Mobile Systems
        - Foreground Process - controlled via user interface
        - Background Process - in memory, running, but not on display, cost on resources if background process number grows unbounded
    - Queues
        - Ready Queue - linked list of PCBs
        - Device Queue - for each device, a linked list of PCBs, offloaded work for file access
    - Process Creation - fork() and exec()
        - Tree of Processes in Linux
            - Create first process - must load this process directly from memory on init, must be coded and defined e.g. assembly language
            - Process ID 1 - starts other procesess
            - Question - every process is a child of what process? init
        - fork() - system call to create a new process, why, duplicate of parent, change PCB to new contents i.e. new program
        - exec() - system call used after fork() to create a new process
        - exit() - system call used to end execution
        - wait() - system call used by parent to wait for child
        - If parent or child never terminate, they never release their resources
        - Improvement - dont copy all data if all is not going to be used, waste of energy
    - Process Termination
        - Cascading termination - all children etc
        - How is Chrome like a mini operating system? Multiple processes that handle specific tasks
    - Interprocess Communication
        - Message Passing
            - Good - process are isolated, security
            - Bad - messages add overhead
        - Shared Memory
            - Good - fast, easy to setup, good performance
            - Bad - if any process corrupts memory, it affects the other, security
        - Cooperasting Processes
            - Independent - process cannot affedct or be affected by exeuction of another
            - Cooperating - process can affect or be affected by execution of another process
        - Direct Communication
            - Process A -> Process B
            - A communication link must be established
        - Indirect Communication (Mailbox)
            - Messages are directed and received from mailboxes
            - Link established if process share a common mailbox
        - Communication
            - stdin, stdout, stderr
            - dir | sort > output.txt
    - Synchronization
        - Blocking (synchronous, order is preserved, wasting time)
            - Blocking Send - sender is blocked until the message is received
            - Blocking Receive - receiver is blocked until a message is available
        - Non-Blocking (asynchronous)
            - Non-Blocking Send - sender sends the message and continues
            - Non-Blocking Receive - receiver receives valid or null
    - Buffering
        - Queues of messages attached to the link
        - Zero Capacity - no messages are queued
        - Bounded Capacity - sender must wait if link full
        - Unbounded Capacity - sender never waits
    - Socket
        - Endpoint for communication, IP and Port
        - < 1024 are well known ports
        - 127.0.01 - loopback
    - Pipe
        - Conduit allowing two processes to communicate
        - Ordinary Pipe - parent child relationship, unidirectional, producer writes to one end, consumer reads from other end
        - Direction: Unidirectional vs. Bidirectional
    - Signals
        - Events emitted, that can be processed with a signal handler to perform a certain task
        - Security - how do you avoid signals emitted from programs from affecting others? - user control
    - Threads
        - Concurrency vs. Parallelism
            - Concurrency - multiple processes on single core
            - Parallelism - multiple concurrent processes on multiple cores
        - Single Thread vs. Multi Threaded
            - Threads can share code, data, and files
            - Threads have their own registers and stack
            - Context Switch between threads in the same process is faster than context switch between two processes

4. 09/26/2024
    - Threading
        - Single and Multithreaded Processes
            - Why? - share relevant context data of the process with multiple workers and avoid context switching
            - Issue - sharing data requires sophisticated technique
            - What - thread includes regsiters, staack, and shares code, data, and files
        - Amdahl's Law
            - The serial portion of the program constraints the speed up granted by multiple cores
            - Key - you CAN'T always parallelize all of the program
            - SpeedUp = 1 / (S + ((1-S)/N)), as N approaches infinity i.e. # of cores, speed up approaches 1/S
        - User Threads and Kernel Threads
            - User Threads - management done by user-level threads library
                - POSIX Pthreads
                - Window Threads
                - Java Threads
            - Kernel Threads - supported by the kernel
        - Models
            - Many User Threads to One Kernel Threads
                - Pro - one kernel space thread dedicated to process
                - Con - any thread using kernel causes all to block
            - One User Threads to One Kernel Threads
                - Pro - more concurrency than many to one
                - Con - number of threads per process may be restricted
            - Many User Threads to Many Kernel Threads
                - Con - difficult to implement
            - Two Level Model
                - Pro - combination of benefits from different models
                - Con - difficult to implement
        - Thread Libraries
            - User Space Library
                - Pro - issues do not affect kernel
                - Con - if thread needs access to kernel
            - Kernel Space Library
                - Pro - can map one to one
                - Con - issues affect entire system
            - Pthreads - standard mechanism API for thread creation, not necessarily successful
            - Implicit Threading - creation and management of threads done by compilers and runtime libraries
                - Thread Pools - benefit for short running threads with overhead, instead leave created threads unallocated till needed, can create upper limit on threads
                - OpenMP - identify parallel region, create as many threads as there are cores
                - Grand Central Dispatch - identify parallel sections, add to dispatch queue and assign available thread when removed
                    - Serial - FIFO order remove one at a time
                    - Concurent - FIFO order remove as group
        - Linux Threads Clone - more control
        - Signal Handling
            - Signal - notify a process that a event has occurred
            - Signal Handler
                - Signal is generated by event
                - Signal is delivered to a process
                - Signal is handled by one of two signal handlers
                    - Default
                    - User Defined
            - Signal Handling
                - Deliver signal to the thread which the signal applies
                - Deliver signal to every thread in process
                - Deliver signal to certain threads
                - Assign a thread to receive all signals
            - Thread Cancellation
                - Deferred - thread finishes
                - Asynchronous - terminate thread immediately
            - What - misbehaving thread, signal sent, is single thread or entire process killed?
            - What - stopping thread and losing intermediate values
                - Thread Local Storage - allows each thread to have its own copy of data, maintain state across invocation
    - Remote Procedure Call
        - What - take advantage of doing calculations on a remote system, returning results to the client
        - Client/Server Communication
            - Server - program or collection of programs that provide a service
            - Client - program that uses the service, sends requests to perform actions and server responds with data
        - Messages
            - Issue - manual, lack of standardization, scaling
        - Procedure Calls
            - What - servers export a set of procedures that can be called by client programs
            - How - clients do a local procedure call, as though they were directly linked with the server
        - Issues
            - How do we make the remote part of RPC invisible?
            - What are the semantics?
            - How do we connect to servers?
            - How do we handle heterogenity?
            - How do we make it fast?
        - RPC Model
            - Server defines interface using Interface Definition Language i.e. names, parameters, and types for all client callable server procedures
            - Stub Compiler - reads IDL declarations and produces stub procedures
                - Server Programmer implements service procedures and links to server side stubs
                - Client Programmer implements client procedures and links to client side stubs
                - Stub manages communication between client and server
        - Marshaling - packing of procedures parameters into a message packet
            - Conversion of Big-Endian to Little-Endian and reverse
            - When data is sent, convert from host to standard network format
            - When data is sent, convert from standard network format to host
        - Binding - process of connecting client to the server
            - Server Start Up - export interface, identify iteself to name sever, tells RPC it is up
            - Client Start Up - import server, RPC runtime finds location and establishes a connection
        - Goal - make Remote Procedure Call look like a local call
        - Issues
            - Remote Service address space is different from clien 
            - Machines and Networks fail
            - Passing Reference Parameters
                - Replace with Pass by Copy/Restore
                - Need to know size of data to copy
            - Remote Process Loop
            - Partial Failures
            - Latency
            - Memory Access
        - Partial Failures
            - Strawman Solution - reboot every time
            - Break Transparency
                - Exactly Once - impossible
                - At Least Once - idempotent, run function again and answer does not change
                - At Most Once - zero, dont know, or once
                - Zero or Once - transactional, makes sense in practice

5. 10/3/2024 -

6. 10/10/2024 -
    - CPU Scheduling
        - Multilevel Feedback Queue
            - Types of Processes
                - System - high priority, low quantum
                - Interactivv
                - Batch
                - Student - low priority - high quantum
            - Action - move processes through queues by increasing priority
        - Thread Scheduling
            - User Level Thread
            - Kernel Level Thread
            - Note - when threads are supported, threads are scheduled instead of processes
            - Process Contention Scope - fair allocation per process, priority set by programmer
            - System Contention Scope - all threads in contention with all other threads
        - Multiprocessor Scheduling
            - Symmetric Multiprocessing - each processor is self scheduling, all processses in commoon ready queu
            - Processor Affinity - process has affinity for processor on which it is currently running
                - Soft Affinity - will run on another processor, attractive for trying to maximize processor use
                - Hard Affinity - will only run on dedicated processor, may result in idle processor
                - Switching
                    - Cache is an issue when switching to new processor, which will slow down the CPU
            - Load Balancing - attempt to keep workload evenly distributed across all processors
                - Push Migration - push  task from overloaded CPU to another CPU
                - Pull Migration - idle processors pull waiting tasks from busy processor
        - Multithreaded Multicore System
            - Thread - rotate between compute and memory to ensure CPU and I/O bound jobs are always 
        - Real Time CPU Scheduling
            - Soft Real Time - no guarantee as when critical real time process will be scheduled
            - Hard Real Time - task must be serviced by its deadline i.e. fixed time interval
            - Latencies
                - Interrupt Latency - time from arrival of interrupt to start of routine that services interrupt
                - Dispatch Latency - time for schedule to take current process off CPU and switch to another
                - Time Frame - Interrupt Processing + Dispatch Latency + Real Time Process Execution
            - Priotity Based Scheduling
                - Scheduler must support preemtive, priority based scheduling, and ability to meet deadlines
                - Periodic - ones require CPU at constant intervals
            - Rate Monotonic Scheduling
                - Priority - assigned based on the inverse of its period
                - Short Period = High Priority
                - Long Period =  Lower Priority
                - Missed Deadlines
                    - As you mix odd integer intervals may result in missed deadlines, we need integer multiples
                - Earliest Deadline First Scheduling - priorities are assigned according to deadlines
                    - Earlier the deadline, higher the priority
                    - Later the deadline, lower the priority
        - Linux Scheduling
            - Version 2.54 - Constant Order Scheduling - Priority
                - Realtime != Meeting Deadline
                - Lower numerical jobs has a higher priority i.e. scheduled more quickly
                - Nice, allowing to give up priority, to reduce priority
                - Issue = poor response time for interactive processes
                - Red Black Trees - grab highest priority job in as little time as possible
                    - When CPU is available, can rebalance the tree for the highest priority
                - Virtual Run Time - tracked, scheduler picks task with lowest virtual run time to run
        - Windows Scheduling
            - Priority Based Preemptive Scheduling
            - Highest priority thread runs next
        - Algorithmic Evaluation
            - What - How to select CPU scheduling algortithm for an OS?
            - Deterministic Modeling - analytic evaluation, take a predetermined workload and define performance of each algorithm for that workload
                - For each algorithm, calculate minimum average waiting time
                - Problem - how to scale this simulation to large numbers of processes and threads
            - Queueing Models
                - Describe the arrival of processes, and CPU and I/O bursts probabilistically
                - Commonlyl exponentialy and described by mean, statistical distribution
                - Computes average throughput, utilization, waiting time, etc.
            - Simulations
                - Generate random CPU or I/O bursts and arrival times
                - Run simulation with particular scheduling and evaluate performance statistics
    - Deadlock 
        - Four Simultaneous Necessary Conditions
            - Mutual Exclusion - only one process at a time can use a resource
            - Hold and Wait - a process holding at least one resource is waiting to acquire additional resources held by other processes
            - No Preemption - a resource can be released only voluntarily by the process holding it
            - Circular Wait - set of processes each waiting for a resource held by another process
        - Deadlock - NONE of the tasks can make progress on their individual job
            - Reality - if deadlock occurs, quit and give up
        - Resource Allocation Graph
            - Process - running process
            - Resource - critical section resource
            - Request Edge - directed edge from process to resource
            - Assignment Edge - directed edge from resource to process
            - Example One - not deadlock, if process 3 finishes and relinquishes R3, the remaining processes will run
            - Example Two - deadlock, circular wait
            - Example Three - cycle but no deadlock, one process has a resource and needs nothing else
            - Facts
                - If no cycles -> no deadlock
                - If cycle ->
                    - if only one instance per resource type, then deadlock
                    - If several instances per resource type, possibly deadlock
        - Handling Deadlocks
            - Deadlock Prevention
                - Remove mutual exclusion
                - Remove hold and wait - when requesting a resource, cannot be holding another
                - Add Preemption - release all resources if requesting a held resource
                - Remove circular wait - impose a total ordering of all resource types, must request in particular order
            - Deadlock Avoidance
                - A Prioi - all processes need to know resources required, impossible
                - Safe State - for all processes the resources needed can be satisfied with cur∂rently available resources
                - Facts
                    - If system in safe state -> no deadlocks
                    - If system in unsafe state -> possibility of deadlock
                - Algorithms
                    - Resource allocation graph
                    - Banker's Algorithm
                        - Each process makes claim
                        - When requesting process must wait
                        - When all resources obtained, must return in finite time
            - Allow Deadlock and Recover
                - Detect Deadlock
                - Wait for Graph - search cycle, if cycle there is exists a deadlock, algorithm is O(n^2 x m)
                - What do you do when a deadlock is detected? Recent, long running, short?
            - Ignore and Pretend - Life
    - Networking
        - Review computer_networking_a_top_down_approach

7. 10/17/2024
    - Networking
        - Packet Switching - large messages are broken down into smaller segments called packages
            - Why - individual packets can traverse the internet in different paths
            - Why - users are bursty, which makes dedicated circuits less attractive
            - Why - individual packets can adapt to network conditions
            - Why - data arriving without error, reduce size of what is sent to reduce possibility of error
            - Issue - congestion possible
            - Issue - packet delay
            - Issue - packet loss, indirect knowledge requiring resend
        - Circuit Switching - dedicated end to end resources
            - Why - large telecom industries if constantly sending data
        - Network of Networks
            - Tier 1 Internet Service Providers, Regional Internet Service Providers, Content Provider Network, Access Internet Service Provider
        - Metrics
            - Packet Loss
            - Throughput - average rate from end to end, smallest communication channel limits throughput
        - Internet Protocol Stack
            - Application - HTTP, SMTP, FTP
            - Transport - TCP, UDP - process to process data transfer
            - Network - routing datagram
            - Link - data transfer between neighboring network elements, Ethernet, WiFi
            - Physical - bits on the wire
        - Open System Interconnection Model
            - Physical
            - Data
            - Network
            - Transport
            - Sessions
            - Presentation
            - Application
        - Encapsulation
            - Structure
                - Applicaiton - prepare message
                - Transport - break message into segments w/ TCP or UDP Header
                - Network - add IP header
                - Link - transfer to next device
                - Physical - bits on the wire
            - Idea
                - Choosing size of M is important, should be larger than headers to make trip worth it
        - Attacks
            - Distributed Denial of Service - overwhelm resource with bogus traffic
            - Packet Sniffing - capture and analyze packet traffic
            - IP Spoofing - send packet with false source address
    - Applications
        - Client Server Architecture
            - Structure
                - Server - always on host, permanent IP address
                - Client - communicate with server, dynamic IP address, does not communicate directly to other clients
            - Benefits
                - Security of server
            - Issues
                - Scaling requires adding servers - linearly
        - Peer to Peer
            - Structure
                - End User - Client and Server
            - Benefits
                - Scales as new peers are added - logarithmic
            - Issues
                - Security is reduced in this situation, a malignant peer can alter and send bad data directly to others
        - Process Communication
            - Processes
                - Client - initiates communication
                - Server - waits to be contacted
            - Sockets
            - Addressing
            - Protocols
                - Message Type e.g. request, response
                - Message Syntax - fields in message
                - Semantics - meaning of information in fields
                - Rules - when and how processes send and respond
        - Transport Service
            - Data Integrity, Timing, Throughput, Security
        - Internet Transport Protocol Services
            - TCP
                - Reliable Transport - was something sent or not
                - Flow Control - sender wont overwhelm receiver
                - Congestion Control - throttle send when network overloaded
                - Connection Oriented - setup required between client and server processes
                - NO: timing, minimum throughput guarantee, security
            - UDP
                - Unreliable Data Transfer
                - NO: reliability, flow control, congestion control, timing, throughput, guarantee, security
        - Securing TCP
            - Secure Socket Layer - provides encrypted TCP connection
        - HTTP
            - Persistent - maintain a connection
            - Non-Persistent - establish connection, complete request and response, close connection
        - Web Caches - satisfy clients without involving origin server
            - How do we store information?
            - How do we track information?
            - How do we know the freshness of data?
            - Conditional Get - if modified since - 304 Not Modified or Modified, faster than downloading entire asset
    - Distributed Name Service DNS
        - What - hostname to IP address translation
        - What - distributed to avoid single point of failure, handle request volume, and perform maintenance
        - Structure
            - Root DNS Servers - 13 root level
            - Top Level Domain Servers - com, org, edu
            - Authoritative Domain Server - organizations own DNS server
        - Issue - when creating initial link, entries must be entered manually to server
        - Iterated - local dns repeatedly queries domains upward until it finds an answer
        - Recursive - dns servers query their higher tier and return responses, a lot of pressure on root server
        - Records
            - A - hostname to IP address
            - NS - hostname of authoritative name server for domain
            - CNAME - canonical e.g. closer versions ford.com to ford.jp
            - MX - mailserver to name
        
