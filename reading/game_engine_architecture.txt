Title: Game Engine Architecture
Authors: Jason Gregory

Summarization of Content

Chapter 1 - Introduction
    a. Structure of a Typical Game Team
        - Engineers - design and implement the software that makes the game and tools work
        - Artists - produce the artistic content
            - Concept, 3D Modelers, Texture, Lighting, Animations, Motion Capture Actors, Sound Designers, Voice Actors
        - Game Designers - design interactive portion of the player's experience i.e. gameplay
        - Producers - manage schedules, serve in design capacity, liasion between development and business teams
        - Marketing, IT, Leadership, Administrative, and Janitorial
    b. What is A Game?
        - Soft Real-Time Interactive Agent-Based Computer Simulations
    c. What is A Game Engine?
        - Software system made up of various components that enable the development of games
    d. Game Genres
        - FPS, MMO, RPG, Racing, Fighting, Platformers, Strategy, Player Authored Content, Virtual, Augmented, and Mixed Reality, Sports, Puzzles
    e. Examples of Game Engines
        - Quake Family for FPS
        - Unreal Engine
        - Half-Life Source Engine
        - Dice's Frostbite
        - Rockstar Advanced Game Engine
        - CRYENGINE
        - Microsoft's XNA Game Studio
        - Unity
        - Open Source: Panda3D, Yake, Torque, Crystal Space
    f. Runtime Engine Architecture
        - Target Hardware - Microsoft Windows, Linux, PS4, Xbox One X
        - Device Drivers - manage hardware resources and shield the operating system and upper engine layers from hardware device details
        - Operating System - orchestrates the executions of programs on a computer
        - Third Party SDKs and Middleware
            - Data Structures and Algorithms: Boost, Folly, Loki
            - C++ Standard Library and STL
            - Graphics - Glide, OpenGL, DirectX, Edge, Vulkan
            - Collision and Physics - Havok, PhysX, Open Dynamics Engine
            - Character Animation - Granny, Havok Animation, OrbisAnim
            - Biomechanical Character Models - Endorphin and Euphoria
        - Platform Independence Layer - shields the engine from knowledge of the underling platform
        - Core Systems - Assertions, Memory Management, Unit Testing, Math Library, Debugging, Movie Player, Engine Config, Curves and Surface Library
        - Resource Manager - interface for accessing any and all types of game assets and other engine input data
        - Rendering Engine
            - Low Level Renderer - render geometric primtives as quickly as possible
            - Graphics Device Interface - initalize graphic devices and set up render surfaces
            - Others - Materials and Shaders, Statis and Dynamic Lighting, Cameras, Text and Fonts, Primitive Submission, Viewports and Virtual Screen, Textures and Surface Mgmt.
            - Scene Graph/Culling Optimizations - limit the number of primitives subimtted for rendering
                - Options: Frustrum Cull, Spatial Subdivision/Scene Graph
            - Visual Effects - particles, decals, light and environment mapping, dynaimc shadows, full screen post effects (high dynamic range, full screen anti-aliasing, bloom)
            - Front-End - heads up display, menus, console, and other development tools, graphical user interface, full motion video, in-game cinematics
        - Profiling and Debugging Tools - profiling the performance of your game (timing, statistics, memory usage, debugging logs)
        - Collision and Physics - dynamics simulation
        - Animation
            - Sprite, Rigid Body Hierarchy, Skeletal Animation, Vertex Animation, Morph Targets
        - Human Interface Devices - devices through with which users interact with or control the game
            - Keyboard, joybad, mouse, controllers
        - Audio
        - Online Multiplayer/Networking
        - Aritificial Intelligence
        - Gameplay Foundation Systems
            - Game Objects and Object Models
            - Event System
            - Scripting System
            - Game Specific Subsystems
    g. Tools and the Asset Pipeline
        - Digital Content Creation Tools
            - Maya, Autodesk, Blender, Adobe Photoshop
        - Asset Conditioning Pipeline - converting from DCC format to optimized format for game
            - 3D Model/Mesh Data - complex shapes composed of triangles and vertices
            - Brush Geometry - collection of convex hulls defined by multiple planes
            - Skeletal Animation Data - mesh, skeletal hierarchy, and animatiomn clips
            - Audio Data
            - Particle Systems Data
        - World Editor
        - Resource Database
        - Web Based User Interfaces

Chapter 2 - Tools of the Trade
    a. Version Control - permits multiple users to work on a group of files collectively
        - Benefits
            - Central repository to share code
            - Keeps history of changes to all files
            - Mechanism to tag and retrieve versions of files
            - Enables branching for feature development and testing
        - Common Version Control Systems
            - Source Code Control System and Revision Control System, Concurrent Version System, Subversion, Git, Perforce, NxN Alienbrain, ClearCase
        - Important Features
            - Updating And Committing, Check-Out, Branching, and Merging
    b. Compilers, Linkers, and IDEs
        - Source Files/Translation Units - source code
        - Header File - share information such as type declarations and function prototypes between translation units
        - Libraries, Executables, and Dynamic Link Libraries
            - Libraries - groups of object files
            - Executable - linked libraries and object files
            - Dynamic Link Library - acts like a hybrid between a regular static library and an exceutable
        - Projects and Solutions
            - Project - collection of source files which, when compiled, produce a lirbary, an executable, or a DLL
            - Solution File - manages collections of projects
        - Build Configuration
            - Build Options - preprocessor, compiler and linker settings
        - Local and Global Optimizers
            - Algebraic simplification, code inlining, constant folding, constant propogation, loop unrolling, dead code elimination, and instruction reordering
        - Typical Build Configurations - Debug, Development, and Ship
        - Techniques - Setting breakpoints, stepping through, using watch windows
        - Important Skills
            - Reading and stepping through disassembly in the debugger
            - Use registers to deduce variables' values and addresses
            - Inspect variables and objects content by address
            - Leverage static and global variables
            - Modify the code
    c. Profiling Tools - measures execution time of code
        - Types - statistical profilers and instrumenting profiles
    d. Memory Leak and Corruption Detection
        - Memory Leak - memory is allocated but never freed
        - Memory Corruption - program inadvertently writes data to the wrong memory location, overwriting important data while failing to update where data should have been
    e. Other Tools - Diff Tool, Three-Way Merge, Hex Editors

Chapter 3 - Fundamentals of Software Engineering for Games
    a. C++ Review and Best Practices
        - Object Oriented Programming
            - Classes and Objects
                - Class - collection of attributes (data) and behaviors (code)
                - Object - instance of a class
            - Inheritance - new classes defined as extensions to preexisting classes
            - Multiple Inheritance - class can have more than one parent class
            - Polymorphism - allows a collection of objects of different types to be manipulated through a single common interface
            - Composition and Aggregation
                - Composition - practice of using a group of interfacing objects to accomplish a high-level task (has-a)
                - Aggregation - (uses-a)
            - Design Patterns
                - Creational, Structural, and Behavioral
            - Janitors and RAII
                - Janitor - construct a local instance ofthe class to acquire the resource, and let it fall out of scope to release it automatically
                - RAII - resource acquisition is initialization pattern
        - C++ Language Standardization
            - C++98, C++03, C++11, C++14, C++17
            - Coding Standards
                - Interface are king
                - Good namds encourage understanding and avoid confusion
                - Don't clutter the global namespace
                - Follow C++ Best Practices
                - Make errors stick out
    b. Catching and Handling Errors
        - Types of Errors:  User and Programmer
        - Handling Errors
            - Handling Player Errors - cue, provide information, gentle redirection
            - Handling Developer Errors
                - Make the error obvious
            - Handling Programmer Errors
                - Assertion system - erro-checking code and arragned for failed error checks to halt the program
            - Implementation fo Error Detection and Handling
                - Error Return Codes
                - Exception Handling
                - Assertions - line of code that checks an expression
                 Compile-Time Assertions
    c. Data, Code, and Memory Layout
        - Numeric Representation
        - Numeric Bases 
            - Base Ten - 7803 = 7*1000 + 8*100 + 0*10 + 3*1
            - Hexadecimal - 0-9 and A-F (10-15)
            - Signed and Unsigned Integers
                - 32-bit unsigned 0x00000000 to 0xFFFFFFFF
                - 32-bit signed - positive = 0x00000000 to 0x7FFFFFFF and negative = 0x80000000 to 0xFFFFFFFF
            - Fixed Point Notation
            - Floating Point Notation
            - Precision and Magnitude - precision increases as magnitude decreases e.g. 10.0000000000 vs 100000000.12
            - Subnormal Values - Gap between 0 vs. 1.175x10^-38
        - Primitive Data Types
            - char ,int, short, long, float, double, bool
            - Custom - F32, U8, U16, I16, U32, U64, I64 and Signed Set
        - Endianess
            - Little-endian - stores least significant byte of a multibyte value at a lower memory address than the most significant byte
            - Big-endian - stores the most significant byte of a multibyte value at a lower memory address thatn the least significant byte
        - Kilobytes vs. Kibibyte
            - Kilobyte - 1000, Kibibyte - 1024
            - Mebibyte - Kibibyte Squared
            - Gibibyte - Kibibyte Cubed
            - Tebibyte - Kibibyte Quadrupled
            - Pebibyte - Kibibyte Quintupled
            - Exbibyte - Kibibyte Sextupled
            - Zebibyte - Kibibyte Septupled
            - Yobibyte - Kibibyte Octupled
        - Declaration, Definitions, and Linkage
            - Declaration vs. Defintion
                - Declaration - decsription og data object or function
                - Definition - describes a unique region of memory in the program
            - Linkage
                - External Linkage - definition is visible to and can be referenced by translation units other than the one in which it appears
                - Internal Linkage - definition can only be seen inside the translationu unit in which it appears
        - Mmeory Layout of a C/C++ Program
            - Executable Image (Executable and Linking Format) e.g. elf or .exe
                - Divided into contiguous blocks called segments or sections
                    - Text, Data, BSS (Block Started by Symbol),  Read-only Data Segment
            - Program Stack
                - Contiguos areas of memory are psuhed and popped off the program stack
                - Stack Frame - return address, CPU registers, local variables
            - Dynamic Allocation Heap - block of memory for each running process from which memory can be allocated and freed
            - Member Variables
                - Class-Static Members - restrict visibility of variable or function to only visibble within this .cpp file
            - Object Layout in Memory
                - Box for Class, Horizontal Lines Separating Data Members
                - Alignment and Packing
                    - Every data type has a natural alignment, which must be respected in order to permit the CPU to read and write more effectively
                    - Packing - aligning properly to ensure best memory usage and reduce holes
   d. Computer Hardware Fundamentals
        - Anatomy of a Computer
            - CPU - Central Processing Unit
                -  ALU, FLU, VPU, MC, Registers, Control Unit
            - ALU - Arithmetic Logical Unit, performs unary and binary arithmetic operations
            - FPU - Floating Point Unit, performs floating-point calculation
            - VPU - Vector Processing Unit, integer and floating-point arithmetic
            - MMU - Memory Management Unit
            - Registers - high-speed memory cells, typically located on chipa and in-close proximity to the components that access them
                - Instruction Pointer - contains address of the currently executing instruction in a amchine language program
                - Stack Pointer - address of the top of the program's call stack
                - Base Pointer - based address of the current function's stack frame on the call stack
                - Status Register/Condition Code Register/Flags Register - contains bits that reflect the result of the most-recent ALU operation
            - Register Formats
                - 32-bits, 64-bits, 80-bits
            - Control Unit - manages the flow of data within a cpu
            - Clock - periodic square wave signal, rising and falling edge of this signal is known as a clock cycle
            - Processing Power - MIPS (Milliosn of Instructions Per Second) or FLOPS (Floating Operations Per Second)
            - Memory - Read-Only Memory (ROM, PROM, EEPROM) and Random Access Memory (RAM, DRAM, SRAM)
            - Buses - data is transferred between the CPU and memory over connections called buses
            - Bus Widths - bits size that controls the range of possible addresses that can be accessed by the CPU
            - Words - frequently a multibyte value, e.g. 16bits or two bytes, two word is 32 bits, four word is 64 bits
            - Machine and Assembly Langauge
                - Instruction Set Architecture - set of instructions supported by a given CPU
                    - Categories - move, arithmetic operations, bitwise operations, shift/rotate operators, comparison, jump and branch, push and pop, functional call and return, interrupts, other
                - Machine Language - instructions encoded numerically
                    - Opcode - which operation to perform e.g. add, subtract, move, jump, etc
                    - Operands - inputs and/or outputs of instruction
                    - Options - addressing mode and other flags
                - Assembly Language - text based verison of machine language
                - Addressing Modes
                    - Register Addressing - values can be transferred from one register to another
                    - Immediate Addressing - operands are target register and the immediate value to be loaded
                    - Direct Addressing - allows data to be moved to or from memory
                    - Register Indirect Addressing - targeted memory address is taken from a register, rather than being encoded as a literal value in the operands
                    - Relative Addressing  - target memory address is specified as an operand, and the value stored in a specific register is used as an offset from that target memory address
    e. Memory Architectures
        - Memory Mapping
            - Memory Mapped I/O  - CPU can perform I/O operations on a peripheral device by reading or writing addresses as if they were just ordinary RAM
            - Video RAM - range of memory addresses assigned for use by a video controller is known as video RAM
        - Virtual Memory
            - Virtual Memory System - memory addresses used by a program don't map direcvtly to the memory modules installed in the computer
            - Virtual Memory Pages - entire addressable memory is organized into equally-sized contiguous chunks known as pages
            - Virtual to Physical Address Translation - page index is looked up by CPUs MMU in  page table that maps virtual page indices to physical ones
            - Handling Page Faults -  access to pages that have been swapped out involves reading page from swap into RAM page and then translating virtual addresses to physical addresses 
            - Translation Lookaside Buffer TLB - caching mechanism for commonly used page table entries
        - Memory Architectures for Latency Reduction
            - Memory Access Latency - length of time between the moment the CPU requests data from the memory system and the moment the data is actually received by the CPU
            - Memory Gap - difference between CPU performance and the performance of memory
                - Techniques for reducing latency
                    - Place smaller, faster memory banks closer to the CPU core
                    - Hiding latency by arranging CPU to do other work while waiting for memory operation to complete
                    - Minimizing access to memory by arranging a program's data as efficiently as possible
            - Memory Cahce Hierachies - primary mechanicm for mitigating impacts of high memory access latencies (L1, L2, L3 Caches)
            - Cache Lines - contiguous blocks of data in caches to take advantage of spatial and temporal locality
            - Set Associativity and Replacement Policy
                - Direct-Mapped - map of one cache line to one main RAM address
                - Associative - two or more distinct cache lines mapped to one main RAM address (ways)
                - Replacement Policy - when a cache miss occurs, which way should be removed e.g. NMRU, LRU, FIFO, LFU
            - Multi-Level Caches - level 1 to level n caches to avoid cache misses
            - Instruction Cache - used to preload excutable machine code before it runs
            - Data Cache - used to speed up read and write operations performed by the machine code
            - Write Policy - how cache controller handles writes
                - Write-Through - all writes to the cache are mirroed to main RAM immediately
                - Write-Back - data is first written into the cache and the cache line is only flushed out to main RAM under certain circumstances
            - Cache Coherency - data in the caches belonging to multiple cores match one another and the contenst of main RAM
                - MESI - Modified, Exclusive, Shared, Invalid
                - MOESI - Modified, Owned, Exclusive, Shared, Invalid
                - MESIF - Modified, Exclusive, Shared, Invalid, Forward
            - Avoiding Cache Misses - organize data in contiguous blocks that are small as possible and access them sequentially
            - Nonuniform Memory Access NUMA and Uniform Memory Access UMA
                - UMA - computer contains a single large bank of main RAM which is visible to all CPU cores in the system
                - NUMA - each core is provided with a relatively small bank of high-speed dedicated RAM called a local store

Chapter 4 - Parallelism and Concurrent Programming
    a. Defining Concurrency and Parallelism
        - Concurrency - utilziing multiple flows of control to solve a problem
        - Parallelism - any situation in which two or more distinct hardware components are operating simulataneously
            - Implicit vs. Explicit Parallelism
                - Implicit (Instruction Level Parallelism) - use of parallel hardware components within a CPU for the purpose of improving the performance of a single instruction stream
                    - Examples: pipelining, superscalar architecture, very long instruction word
                - Explicit Parallelism - use of duplicated hardware components within a CPU, computer, or computer system, for the purpose of running more than one instruction stream simultaneously
                    - Examples: Hyperthreaded CPUs, mutlicore CPUs, multiprocessor computers, computer clusters, grid computing, cloud computing
        - Task vs Data Parallelism
            - Task Parallelism - multiple heterogenous operations are performed in parallel (animation calculations)
            - Data Parallelism - single operation is performed on multiple data items in parallel
        - Flynn's Taxonomy
            - Single Instruction Single Data - single instruction stream operating on a single data stream
            - Multiple Instruction Multiple Data - multiple instruction streams on multiple independent data streams
            - Single Instruction Multiple Data - a single instruction stream operating on multiple data streams
            - Multiple Instruction Single Data - multiple instructions streams all operating on a single data strea
            - Single vs. Multiple Data
                - Single data refers to a single pair of inputs
                - SISD - single ALU performs the multiple first, followed by the divide
                - MIMD - two ALUs perform operations in parallel, operating on two independent data streams
                - SIMD - wide ALU performs the multiple first, followed by the divide, but each instruction operates on a pair of four element input vectors
                - MISD - two ALUs process the same instruction stream, multiple first followed by divide, and ideally produce identical results
        - GPU Paralleism: SIMT
            - Single Instruction Multiple Thread - single instruction operating on multiple data streams simultaneously with multi-threading
        - Orthogonality of Concurrency and Parallelism
    b. Implciit Parallelism
        - Pipelining
            - Stages - Fetch, Decode, Execute, Memory Access, Register Write-Back
            - Goal - begin a new instruction on each clock cycle, keeping the CPU busy
        - Latency vs. Throughput
            - Latency - amount of time required to completely process a single instruction (sum of the latencies of all stages of pipeline)
            - Throughput - measure of how many instructions a pipeline can process per unit of time
        - Pipeline Depths - balance throughput with overall latency
        - Stalls - a CPU is unable to issue a new instruction on a particular clock cycle
        - Data Dependencies - later stages of the pipeline are dependent on results of earlier stages
             - Data Dependencies, Control Dependencies, Structural Depedencies
        - Instruction Reordering - reodering instructions, without changing the behavior of the program, to make the most of the pipeline
        - Out-Of-Order Execution - CPUs support out of order execution to dynamically detect data dependencies between instructions and automatically resolve them
        - Branch Dependencies - example where jump cannot occur until results of cmp 
        - Speculative Execution/Branch Prediction - running code along branch in the hopes the CPU chose correctly
            - Branch Penalty - choosing the wrong branch
        - Predication - Execute both branches and then use a mask to produce the final answer
        - Superscalar CPUs - duplicate components on chip so that two instructions can be launched each clock cycle
            - Design can lead to resource dependencies, two or more consecutive instructions all requrie the same CPU functional unit
        - Superscalar and RISC - using reduced instruction set to free up transistors
        - Very Long Instruction Word VLIW - allowing programmers to dispatch instructions to multiple compute elements which requires a longer instruction word
    c. Explicit Parallelism
        - Hyperthreading - selecting instructions from two separate instruction streams
            - HT core consists of two register files and two instruction decode units but with a single back end for executing instructions
        - Multicode CPUs - multiple cores oon a PC
        - Symetric vs. Asymmetric Multiprocessing
            - Symmetric Multiprocessing - available CPU cores in the machine are homogenous in deisgn and ISA and are treated equally by the operating system
            - Asymmetric Multiprocessing - CPU cores are not homogenous and the operating system does not treat them equally
        - Distributed Computing - making use of multiple stand along computers working in concert
            - Examples - computer clusters, grid computing, and cloud computing
    d. Operating System Fundamentals
        - Kernel - layer of operating system that operates at the lowest level and nearest to hardware
            - Kernel Mode vs. User Mode
                - Kernel mode is privileged, allowing the greatest access and power
                - User mode is limited, accessing low level services require a kernel call
                - Protection Rings - inner circle is most trusted, with reduced trust as you become further away
                - Kernel Mode Privileges - access to all of the instructions defined in the ISA, including privileged instruction
            - Interrupts - signal sent to CPU in order to notify it of an important low level event e.g. keypress
            - Kernel Calls - request to kernel to perform a privileged operation, normally through a kernel API
            - Preemptive Multitaksing - programs share the CPU by time-slicing, however the scheduling of programs is controlled by the operating system
        - Processes - operating systems way of managing a running instance of a program
            - Anatomy of a Process
                - Process ID (PID) - unique identifies the process within the operating system
                - Permissions - which user owns each process and which group the user belongs to
                - Parent Process ID
                - Virtual Memory Space - containing the processe's view of physical memory
                - Environemt Variables
                - File Handles
                - Working Directory
                - Synchronization and Communication Resource - sempahores, queues, pipes
                - Threads - encapsualtes a running instance of a single stream of machine language instructions
            - Virtual Memory Map of Process
                - Virtual Table/Memory Map:
                    - Text, Data, BSS - executable files read in so program code and global data is visible within process
                    - Call Stack
                    - Shared libraries - program dependencies
                    - Heap - for dynamic memory allocation
                    - Kernel Pages - separate virtual page table that is shared between all processes
            - Threads - encapsulates a running instance of a single strean of machine language instructions
                - Thread ID - unique identifier within the process
                - Call Stack - contiguous block of memory containing the stack frames of all currently executing functions
                - Special and General Registers
                - Thread Local Storage
                - Thread Libraries - collection of system calls for creating and manipulating threads
                    - Create, Terminate, Request to Exit, Sleep, Yield, Join
                - Thread Creation and Termination
                    - Process executed by the OS automatically contains a single thread, and additional threads can be created using system calls
                    - Threads can end:
                        - Naturally, system call, killed by another thread, and killed by process ending
                - Joining Threads - wait for other threads to finish
                - Polling, Blocking, and Yielding
                    - Polling - single thread sitting in a tight loop, waiting for a condition to become true
                    - Blocking - put thread to sleep and rely on the kernel to wake it up based on some condition
                        - Examples - opening a file, explcit sleeping, joining with another thread, waiting for a mutex lock
                    - Yielding - thread polls the condition in a loop, but on each iteration it relinquishes the remaining of its time slice by yielding
                - Context Switching - switching between thread states
                    - Thread States - running, runnable, blocked
                - Thread Local Storage - private memory block for data that is private to this process, shared with other threads
            - Fibers - cooperative multitaksing mechanism, fibers run within the context of a thread and are scheduled cooperatively by each other
                - Fiber Creation and Destruction
                    - ConvertThreadToFiber(), new fiber is created within the context of the calling thread
                    - DeleteFiber(), destroys fiber
                - Fiber States - Active or Inactive
                    - Active - assigned to a thread and executes on its behalf
                    - Inactive - waiting to be activated, not consuming the resources of any thread
                    -Fibers can deactivate themselves and make another fiber active by calling SwitchToFiber()
                - Fiber Migration
                    - Fibers can migrate from thread to thread, but only by passing through its inactive state
                - Debugging with Fibers - confirm debugger has capability to profile thread 
            - User Level Threads and Coroutines
                - User Level Threads
                    - Allow a programmer to code in terms of multiple independent flows of control, each with its own execution context, but without the high cost of making kernel calls
                    - Implemented entirely in user space with a API
                - Coroutines
                    - generalization of the concept of a subroutine, can exit by yielding to another corouting
                - Kernel Threads vs User Threads
                    - Linux - a special thread created for internal use by the kernel itself, which runs only while the CPU is in privileged mode
                    - any thread that is known to and scheduled by the kernel
    e. Introduction to Concurrent Programming - a workload is broken down into two or more flows of control that can run semi-independently
        - Examples - piped chain commands in Linux or Windows, single process comprised of multiple threads, thread group comprised of multiple threads, video game sharing a common game state between clients
        - Why Write Concurrent Software? - model of multiple semi-independent flows of control matches the problem better than a single flow-of-control design
        - Concurrent Programming Models
            - Message Passing - threads pass messagesa between one another in order to share data and synchornize activities
            - Shared Memory - two or more threads are granted access to the same block of physical memory, and can therefore operate directly on any data objects residing in that memory area
        - Race Conditions - any situations in which the behavior of a program is dependent on timing
            - Critical Races - race condition that has the potential to cause incorrect program behaviour
                - Examples
                    - intermittent or seemingly random bugs or crashes, incorrect results, data structures that get into corrupted states, bugs that magically disappear when you switch to debug build, bugs that are around and go away and return
            - Data Races - critical race condition in which two or more flows of control interfere with one another while reading and/or writing a block of shared data
        - Critical Operations and Atomicity
            - Critical Operation - any operation that can possible read or mutate one particulare shared object
            - Atomicity - critical operation is uninterruptable
            - Invocation and Response
                - Instantaneous Events
                    - Event A happens before Event B
                    - Event A happens after Event B
                    - Event A and B are simultaneous
                - Invocation - moment at which the operation begins
                - Response - moment at which the operation is considered complete
                - Program Order - Preamble Section, Critical Section, Postamble Section
            - Atomicity - an operation whose invocation and response are not interrupted by another critical operation on that same object.
            - Making an Operation Atomic
                - Mutex - object provided by the operating system that acts like a padlock, in that it can be locked and unlocked by a thread
                - Atomicity as Serialization - only one trhread will be performing an operation on a shared data object at a time, orderly sequential sequence of atomic operations
                - Data Centric Consistency Models - contract betwen a data store, such as a shared data object in a concurrent system, and a colleciton of threads that share that data store
    f. Thread Synchonization Primitives
        - Tools that provide
            - ability to share resources between threads by making critical operations atomic
            - ability to synchronize the operation of two or more threads
                - enabling a thread to go to sleep while it waits for a resource to become available or for one or more threads to complete a task
                - enabling a running thread to notify one or more sleeping threads by waking them up
        - Mutexes - operating system object that allows critical operations to be made atomic
            - States - unlocked or locked, released or acquired, signaled or nonsignaled
            - Mutex API - create() or init(), destroy(), lock() or acquire(), try_lock() or try_acquire(), unlock() or release()
                - POSIX - pthread_mutex_t_g, pthread_mutex_lock(), pthread_mutex_unlock()
                - C++ Standard Library - std::mutex, g_mutex.lock(), g_mutex.unlock()
                - Window - HANDLE, WaitForSingleObject(), ReleaseMutext()
        - Critical Sections - Windows Low Cost Mutext
            - IntializeCriticalSection(), DeleteCriticalSection(), EnterCriticalSection(), TryEnterCriticalSection(), LeaveCriticalSection()
        - Condition Variables
            - Producer generates data, consumer consumes data
            - API - create(), init(), destroy(), wait(), notify()
        - Sempahores - atomic counter whose value is never allowed to drop below zero
            - API - init(), destroy(), take() or wait(), give(), post, or signal()\
            - Mutex vs. Binary Semaphore - mutex can only be unlocked by the thread that locked it, sempahore on the other hand can be incremented by one thread and later decremented by another thread
    g. Problems with Lock-Based Concurrency
        - Deadlock - situation in which no thread in the system can make progress, resulting in a hang
            - Conditions
                - Mutual Exclusion - a single thread can be granted exclusive access to a single resource via a mutex lock
                - Hold and Wait - a thread must be holding one lock when it goes to sleep waiting on another lock
                - No Lock Preemption - No one, not even the kernel, is allowed to forcibly break a lock held by a sleeping thread
                - Circular Wait - there must exist a cycle in the thread dependency graph
        - Livelock - threads spend all of their time trying to resolve the deadlock, rather than performing any work
        - Starvation - any situation in which onre or more threads fail to receive any execution time on the CPU
        - Priority Inversion - low priority thread acts as though it is the highest priority thread in the sytem
        - Dining Philosophers - five philosphers sit around a circular table with plate in front and a single chopstick in between
                - Solutions - Global Order, Central Arbitor, Chandra-Misra
    h. Some Rules of Thumb for Concurrency
        - Global Ordering Rules - ordering must be imposed globally across all threads
        - Transaction-Based Algorithms - transaction is an individual bundle of resources and/or operations, transactions are submitted to a central arbiter of some kind
        - Minimizing Contention - reduce times threads have to wait for a lock
        - Thread Safety - API functions can be safely called by any thread in a multithreaded process
    i. Lock-Free Concurrency
        - Practice of preventing threads from going asleep while waiting on a resource to become available
        - Non-Blocking Techniques
            - Blocking - a thread can be put to sleep while waiting for shared resources to become available
            - Obstruction Freedom - guarantee that a single thread will always complete its work on a bounded number of steps, when all of the other threads in the system are suddenly suspended
            - Lock Freedom - in any infinitely long run of the program, an infinite number of operations will be completed
            - Wait Freedom - Lock Freedom and guarantees starvation freedom
        - Causes of Data Race Bugs
            - via the interruption of one critical operation by another
            - by instruction reordering optimizations performed by the compiler and CPU
            - as a result of hardware specific memory ordering semantics
        - Implementing Atomicity
            - Atomicity by disabling interrupts
            - Atomic instructions at the machine language level, atomic reads and writes and atomic read-modify-write instructions
            - Test and Set - simplest read-modify-write instruction, sets a boolean variable to 1 and returns its previous value
            - Exchange - swaps contenst of two registers, or a register and a location in memory
            - Compare and Swap - checks exisitng value in memory location, and atomically swaps it with a new value if and only if the existing value matches an expected value
            - ABA Problem - read sees As values, another thread preempts us, or runs on another core, and writes two values into the location we are trying to atomically update.
            - Load Linked/Store Conditional - load linked reads the value of a memory location atomically and stores the address in a special CPU register known as the link register
                - Advantages of LL/SC over CAS
                    - SC fails whenever any write is performed on the bus, so an LL/SC is not prone to the ABA problem
                    - LL/SC is more pipeline friendly than a CAS instruction
            - Strong and Weak Compare-Exchange
                - Strong compare exchange hides spurios SC failures from the programmer
                - Weak compare exchange does not
            - Relative Strength of Atomic RMW Instructions
                - TAS is weaker then CAS and LL/SC in achieving consensus between multiple threads in a concurrent system
            - How Instruction Reordering Causes Concurrency Bugs
                - CPU can reorder the producer's write so that it occurs before the write of data that informs the consumer
            - Compiler Barriers - a pseudoinstruction that stops the compiler from reordering read and write instructions across critical operation boundaries
            - Memory Ordering Semantics - rules that provide various guarantees about how reads and writes propogate between cores, and they provide programmers with the tools necessary to enforce a particular ordering, when teh default semantics are insufficient
            - Multicore Cache Coherency Protocols - a communication mechanism that permits cores to share data between their local L1 cahces
                - MESI - Modified, Exclusive, Shared, and Invalid
                - MOESI - Modified, Owned, Exclusive, Shared and Invalid
                - How MESI Can Go Wrong - optimizations, some operations are deferred to save time
            - Memory Fences - special machine language instructions to prevent first instructions from passing second, serves as compiler barriers and prevent CPUs out of order logic from reordering instructions across the fence
                - First Instruction Passes Second
                    - a read can pass another read
                    - a read can pass a write
                    - a write can pass another write
                    - a write can pass a read
                - Acquire and Release Semantics
                    - Release - guarantees that a write to shared memory can never be passe dby any other read or write that precedes it in program order
                    - Acquire - guarantees that a read from shared memory can never be passed by any other read or write that precedes it in program order
                    - Full Fence - bidirectional semantic ensures that all memory operations appear to occur in program order across the boundary created by a fence instruction in the code
                - When to Use Acqure and Release Semantics
                    - Write-Release in producer scenarios, in which a thread performs two consecutive writes and we need to ensure that all other threads will see the two writes in the correct order
                    - Read-Acquire used in a consumer scenarios, in which a thread performs two consecutive reads in which the second is conditional on the first
            - Atomic Variables - C++11 class template std::atomic<T> allows virtually any data type to be converted into an atomic variable
                - C++ Memory Order
                    - Read - an atomic operation peformed with relaxed memory order semantics guarantees only atomicity. No barrier or fence is used
                    - Consume - a read performed with consume semantics guarantees that no other read or write within the same thread can be reordered before the read
                    - Release - a write performed with release semantics guarantees that no other read or write in this thread can be reordered after it, and the write is guaranteed to be visible by other threads reading the same address
                    - Acquire - a read performed with acquire semantics guarantees consume semantics and guarantees that writes to the same address by other threads will be visible to this thread
                    - Acquire/Release - supplies a full memory fence
            - Concurency in Interpreted Programming Languages
                - Provide powerful synchronization facilities that are not constrained by the hardware
        - Spin Locks
            - Use TAS instruction to atomically set the flag to true, retrying the value in a while loop until the TAS succeeds. Unlock by atomically writing a value of false into the flag
            - When Acquiring - use read-acquire memory ordering semantics to read the lock's current contents as part of the TAS operation
            - When Releasing - use write-release semantics to ensure that all writes performed after the call to Unlock() aren't observed by other threads as if they had happened before the lock was released
            - Scoped Locks - wrapper to ensure that a lock is automatically released when a particular scope is exited
            - Reentrant Locks - avoid reentrancy by having the lock cache the id of the thread that has locked it
            - Readers-Writer Locks - allows any number of readers to acquire it concurrently, when a writer thread attempts to acquire the lock, it should wait until all readers are finished, and then it should acquire the lock in a special "exclusive" mode that prevents readers and writers from gaining access until mutation has completed\
            - Lock-Not-Needed Assertions - assert a lock isn't required
        - Lock-Free Transactions - avoid taking locks that will either put the thread to sleep ort cause it to get caught in a busy-wait loop inside a spin lock, perform majority of work locally, execute as single atomic instruction
    j. SIMD/Vector Processing -  perform a mathematical operation on multiple data items in parallel, using a single machine instruction
    k. GPGPU Programming - General Purpose GPU Programming
        - GPU - specialized coprocessor designed specifically to accelerate those computations taht involve a high degree of data parallelism
            - Combines SIMD (Vectorized ALUs) with MIMD parallelism, by employing a form of preemptive multi-threading.
            - G argument tells the GPU driver into how many threads groups to divide the wor
            - Cartesian Coordinates - (Px, Py) or (Px, Py, Pz)k

Chapter 5 - 3D Math for Games
    a. Solving 3D Problems in 2D
    b. Points and Vectors
        - Coordinates
            - Cylindrical Coordinates - (Ph, Pr, Ptheta) or Height, Radius and Yaw
            - Spherical Coordinates - (Pr, Pphi, P Ptheta) or Radial, Pitch, and Yawss
        - Left-Handed vs. Right-Handed - difference between the direction one of the three axes are pointing
        - Vectors - quantity with both a magnitude and direction in n-dimensional space (x, y, z)
        - Vector Operations
            - Multiplication by a Scalar - sa = (sx, sy, sz)
            - Additiona and Subtraction - a + b = (ax + bx, ay + by, az + bz) or a - b = (ax - bx, ay - by, az - bz)
            - Magnitude - scalar representing the length of the vectors as it would be measured in 2D or 3D space |a| = sqrt(ax^2, ay^2, az^2)
            - Unit Vector - vector with a magnitude of length 1
            - Normal Vectors - normal to a surface if it is perpendicular to that surface
            - Dot and Cross Produc 
                - Dot Product - dot product of two vectors yields a scalar - a * b = axbx + ayby + azbz = d
                - Cross Product - cross product of two vectors yields another vector that is perpendicular to the two vectors being multiplied
        - Linear Interpolation of Points and Vectors
            - simple mathematical operation that finds an intermediate point between two known points
    c. Matrices - rectangular array of m x n scalars.
        - Matrix Multiplication
        - Representing Points and Matrices - v1 = [1, 2, 3] or vertical 
        - Identity Matrix - a matrix that when multipied by any other matrix, yields the very same matrix
        - Matrix Inversion - inverse of Matrix A is another Matrix A^-1 that undoes the effects of Matrix A
        - Transposition - transpose of a Matrix M is M^T, obtained by reflecting the entities of the original matrix across its diaganol, the rows of the original matrix become the columns of the transposed matrix and vice versa
        - 4 x 3 matrices - 4 x 4 affine matrix always contains the vector [0, 0, 0, 1], as such game programmers omit the fourth column to save memory
        - Coordinate Spaces -  a set of coordiante axes
            - Model Space - origin is placed at a central location within the object
                - Front - axis that points to the directyion that the object naturally travels or faces
                - Up - axis that points towards the top of the object
                - Left or Right - axis that points toward the left or right side of the object
            - World Space - fixed coordinate space, in wich the positions, orientations, and scales of all objects in the game world are expressed
            - View Space - coordinate frame fixed to the camera
            - Change of Basis - conversion of object's position, orientation, and scale from one coordinate system into another
            - Coordiante Space Hierarchies - every coordinate space is a child of some other coordinte space, and the other space acts as the parent
        - Storing Matrices in Memory - two dimensioanl arrays
            - Store contiguously in memory, i.e. each row contains a single vector
            - Store the vectors strided in memory, i.e. each column contains one vector
    d. Quaternions - rotational representation of an object, four dimensional complex number with a single real axis and three imaginary axes represnted by the imaginary numbers i, j, and k
        - Unit Quaternions as 3D Rotations - three dimensional vector plus a fourth scalar coordinate
        - Quaternion Operations
            - Mulitplication - the product of p and q represents that composite rotation, i.e. rotation q followed by rotation p
            - Conjugate and Inverse
                - Inverse is defined as q^-1 and when multiplied by the original yields the scalar 1
                - Conjugate - negate the vector part but leave the scalar part
            - Rotating Vectors with Quaternions
                - Convert vector to quaternion, multiple that by the quaternion and the post multiple by the quaternion inverse q^1
            - Quaternion Concatenation - can be achieved by multiplying the quaternions together
            - Quaternion- Matrix Equivalence - can convert any 3D rotation freel between a 3x3 matrix representation and a quaternion representation
            - Rotational Linear Interpolation - mathematical operation that finds an intermediate roation between two rotations
            - Spherical Linear Interpolation - uses sines and cosines to interpolate along a great circle of the 4D hypersphere
    e. Comparison of Rotational Representations
        - Euler Angles - yaw, pitch, and roll
            - + = simplicity, small size
            - - = gimbal lock, differing order in which rotations are performed PYR, YPR, RYP, and so on, depends on mapping x, y, and z to front, left/right, and up
        - 3x3 Matrices
            - - = not particularly intuitive
        - Axis + Angle
            - + = intuitive, compact
            - - = rotations can not be easily interpolated
        - Quaternions
            - + = permits rotations to be concatenated and applied directly to points and vectors via q multiplication, and permits rotations to be easily interpolated via simple LERP or SLERP operations
        - SRT Transformations - Scale Factor, Rotation Quaternion and Translation Vector
            - + = size and ability to be easily interpolated
        - Dual Quaternions
        - Degrees of Freedom - number of mutually independent ways in which an object's physical state (position and orientaiton) can change
            - Six DOF - three in translation (x, y, x). and three in rotation ( about the x, about the y, about the z)
            - Euler - 3 DOF
            - Axis+Angle - 3 DOF
            - Quaternion - 3 DOF
            - 3x3 Matrix - 3 DOF
    f. Other Useful Math Objects
        - Lines, Rays, and Line Segments, Spheres, Planes, Axis Aligned Bounding Boxes, Oriented Bounding Boxes, Frusta, Convex Polyhedral Regions
    g. Random Number Generation
        - Linear Congruential Genreations
        - Mersenne Twister
        - Mother of All, Xorshfit, and KISS99
        - PCG


Chapter 6 - Engine Support Systems
Chapter 7 - Resources and the File System
Chapter 8 - The Game Loop and Real-Time Simulation
Chapter 9 - Human Interface Devices
Chapter 10 - Tools for Debugging and Development
Chapter 11 - The Rendering Engine
Chapter 12 - Animation Systems
Chapter 13 - Collision and Rigid Body Dynamics
Chapter 14 - Audio
Chapter 15 - Introduction to Gameplay Systems
Chapter 16 - Runtime Gameplay Foundation Systems