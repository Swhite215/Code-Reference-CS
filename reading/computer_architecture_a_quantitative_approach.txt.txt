Title: Computer Architecture: A Quantitative Approach
Authors: John L. Hennessy and David A. Patterson

Summarization of Content

1. Chapter 1 - Fundamentals of Quantitative Design and Analysis
    a. Classes of Computers
        - Personal/Mobile Devices PMD
        - Desktop
        - Server
        - Warehouse
        - IoT/Embedded
    b. Parallelism
        - Data-Level Parallelism
            - Instruction Level Parallelism
            - Vector Architectures, Graphic Processor Units, and Multimedia Instruction Sets
            - Thread Level Parallelism
        - Task-Level Parallelism 
            - Thread Level Parallelism
            - Request Level Parallelism
        - Categories
            - Single Instruction, Single Data Stream SISD
            - Single Instruction, Multiple Data Stream SIMD
            - Multiple Instruction, Singel Data Stream MISD
            - Multiple Instruction, Multiple Data Stream MIMD
    c. Instruction Set Architecture Dimensions
        - Class - General Purpose Registers
        - Memory Addressing
        - Addresing Modes
        - Types and Sizes of Operands
        - Operations
        - Control Flow Instructions
        - Encoding an ISA
    d. Trends in Technology
        - Integrated Circuit Technology
        - Semiconductor DRAM
        - Semiconductor Flash
        - Magnetic Disks
    e. Performance Trends
        - Bandwidth or Throughput
        - Latency or Response Time
    f. Dependability
        - Mean Time to Failure
        - Mean Time Between Failures
        - Mean Time to Recover
    g. Benchmarks
        - Electronic Design News Embedded Microprocessor Benchmark Consortium
        - Standard Performance Evaluation Corporation
        - Transaction Processing Council
    h. Quantitative Principles of Computer Design
        - Parallelism
        - Locality
        - Common Case
        - Amdahl's Law
        - Processor Performance Equation
    i. Fallacies and Pitfalls
        - P: All exponential laws must come to an end.
        - F: Multiprocessors are a silver bullet.
        - P: Falling prey to Amdahl's Law.
        - P: A single point of failure.
        - F: Hardware enhancements that increase performance also improve energy efficiency, or at worst are energy neutral.
        - F: Benchmarks remain valid indefinitely.
        - F: Disks never fail.
        - F: Peak performance tracks observed performance.

2. Chapter 2 - Memory Hierarchy Design
    a. Memory Technology
        - Primary Memory
            - L1, L2, L3 Cache
        - Secondary Memory
            - HDD
            - SDD
            - Optical Drives CD/DVD
        - Caches Misses
            - Compulsory, Capacity, Conflict
        - Six Basic Cache Optimizations
            - Larger Block Size to Reduce Miss Rate
            - Bigger Caches to Reduce Miss Rate
            - Higher Associativity to Reduce Miss Rate
            - Multilevel Caches to Reduce Miss Penalty
            - Priority to Read Misses Over Writes to Reduce Miss Penalty
            - Avoiding Address Translation During Indexing of Cache to Reduce Hit Time
    b. Memory Technology and Optimizations
        - RAM
            - Dynamic RAM - DRAM
            - Static RAM - SRAM
            - Synchronous DRAM - SDRAM
            - Double Data Rate - DDR
            - Graphics SDRAM - GSDRAM
        - Flash Memory
            - EEPROM
        - Phase-Change Memory Technology
    c. Ten Advanced Optimizations of Cache Performance
        - Categories
            - Reducing the Hit Time
                - Small and Simple First Level Caches
                - Way Prediction
            - Increasing Cache Bandwidthq
                - Pipelined and Multibanked Caches
                - Non-Blocking Caches
            - Reducing the Miss Penalty
                - Critical Word First and Early Restart
                - Merging Write Buffer
            - Reducing the Miss Rate
                - Compiler Optimizations
            - Reducing the Miss Penalty or Miss Rate Via Parallelism
                - Hardware Prefetching
                - Compile Prefetching
            - Miscellaneous
                - High-Bandwidth Memory 
    d. Virtual Memory and Virtual Machines
        - Virtual Machine Monitor
            - Provides an environment for programs which is essentially identical with the original machine
            - Programs run in this environment show at worst only minor decreases in speed
            - VMM is in complete control of system resources
        - Protection via Virtual Memory
            - Kernel and User Mode
            - User Process Use w/ supervisor mode bit, exception enable/disable bit, and memory protection information
            - Mechanism to go to supervisor mode and back to user mode
            - Mechanisms to limit memory access without having to swap the process on disk on a context switch
        - Protection Via Virtual Machines
            - Increase importance of isolation and security
            - Failures in security and reliability of standard operating systems
            - Sharing of a single computer among unrelated users
            - Dramatic increases in the raw speed of processors
        - VM
            - All emulation methods that provide a standard software interface
            - Interest: VMs that provide a complete system-level environment at the binary instruction set architecture level
        - VM Benefits
            - Managing Software and Hardware
        - VMM Requirements
            - Guest hardware should behave on a VM exactly as if it were running on the native hardware
            - Guest software should not be able to directly change allocation of real system resources
    e. Pitfalls and Fallacies
        - F: Predicting Cache Performance of One Program from Another
        - P: Simulating Enough Instructions to Get Accurate Performance Measure of the Memory Hierarchy
        - P: Not Delivering High Memory Bandwidth in a Cache-Based System
        - P: Implementing a Virtual Machine Monitor on an Instruction Set Architecture that was not designed to be Virtualizable
3. Chapter 3 - Instruction Level Parallelism
