Title: Operating Systems: Three Easy Pieces
Authors: Remzi and Andrea Arpaci-Dusseau

Summarization of Content

1. Topic #1 - Virtualization of CPU
    a. The Process
        - A running program
        - How can the OS provide the illusion of nearly endless CPUs? 
            - Virtualization
            - Time Sharing (Context Switch)
            - Space Sharing (Partitions)
        - Process Control Block - State of Process
    b. Process API
        - Methods: Create, Destroy, Wait, Miscellaneous, Status
        - States: Ready, Blocked, Runnnig
        - Commands on Linux: ps, top, htop
        - System Calls: fork(), exec(), wait(), kill()
    c. Limited Direct Execution
        - Run directly on the CPU
        - Issues: Restricted Operations, Switching
        - Terms: Run, Trap, Trap/Interrupt Handler, Timer Interrupt, Concept Switch
    d. Scheduling - Introduction
        - Metrics: Turnaround Time, Fairness, Response Time
        - Policies: FIFO, SJF, STCF, Round Robin
    e. Scheduling - Multi-Level Feedback Queue
        - Rule 1: Priority A > Priorty B, A runs.
        - Rule 2: Priority A = Priority B, A & B run in RR.
        - Rule 3: When entering, job is placed at highest priority.
        - Rule 4: Once a job uses its time allotment, its priority is reduced.
        - Rule 5: After some time period, move all the jobs in the system to the topmost queue.
    f. Scheduling - Proportional Share
        - Lottery Scheduling
        - Randomness to Achieve Proportion (Ticket Share Determinant)
        - Stride Scheduling, Deterministic Fair Share Scheduler
    g. Multi-Processor Scheduling
        - Single-Queue Scheduling
        - Multi-Queue Scheduling
2. Topic #2 - Virtualization of Memory
    a. Address Spaces
        - Running processes view of memory in the system
        - Goals: Transparency, Efficiency, Protection
    b. Memory API
        - Methods:
        - System Calls: malloc(), free(), calloc(), realloc()
        - Common Errors: Forgetting to Allocate, Forgetting to Free, Not Allocating Enough
        - More Errors: Forgetting to Initialize, Freeing Memory Before You Are Done, Freeing Memory Repeatedly
    c. Address Translation
        - Hardware transform each memory access, changing the virtual address provided by the instruction to a physical address where the information is located
        - Program has the illusion of it's own memory
        - Base and Bounds, Dynamic Relocation, Add Base to Address, use Memory Management Unit
    d. Segmentation
        - Continuous portion of the address space of a particular length
        - Sharing is enabled through protection bits
        - Coarse-grained = large chunks
        - Fine-grained = small chunks
    e. Free Space Management
        - The problem: external fragmentation and internal fragmentation
        - Mechanisms: Splitting and Coalescing
        - Strategies: Best Fit, Worst Fit, First Fit, Next Fit, Segregated Lists, Binary Buddy Allocator
    f. Paging
        - Splitting up a process's address space into fixed size units called pages
        - Page Frames, are fixed-size slots in physical memory, each containing a single virtual memory page
        - Page Table, a per process structure that records where each virtual page of the address is placed in physical memory
            - Virtual Page Number, Physical Frame Number, and Offset
            - Valid Bit, Protection Bit, Present Bit, Dirty Bit, Reference Bit, 
    g. Translation Lookaside Buffer
        - Part of the Memory Management Unit, cache of popular virtual to physical address translations
        - TLB Hit, virtual to address translation exists
        - TLB Miss, virtual to address translation does not exist
        - Software vs. Hardware Managed
        - Fully Associative, Virtual Page Number, Physical Frame Number, Other Bits
        - Replacement Policies: FIFO, LIFO, LRU, Random
        - Multiple Levels
    h. Beyond Physical Memory Mechanisms
        - Swap Space, reserved space for moving pages back and forth
        - Page Fault, if the present bit is zero, page does not exist, must be swapped into memory
    i. Beyond Phyiscal Memory Policies
        - Metrics: Cache Misses, Cache Hits, Average Memory Access Time
        - Page Replacement Policies: Furthest in the Future, FIFO, Random, LRU, LFU, Prefetching Paging, Demand Paging
        - Issues: Thrashing, system is constantly paging
3. Topic #3 - Concurrency
    a. Concurrency
        - Thread, Point of execution
        - Context Switch, Switching between Processes
        - Thread Control Block - State of Thread
        - Issue: Shared Resource, Uncontrolled Scheduling, Waiting
        - Atomicity: Non-interruptable execution of instruction
        - Synchornization Primitives: Helps achieve concurrency
        - Vocabulary
            - Critical Section, a piece of code that accesses a shared resource
            - Race Condition, multiple threads of execution enter the critical section at roughly the same time, both attempt to update resource
            - Indeterminate, program consists of one or more race conditions
            - Mutual Exclusion, gurantees only a single thread ever enters a critical section
    b. Thread API
        - System Calls: pthread_create(), pthread_join()
    c. Locks
        - Mutual Exlcusion to a critical section
        - Routines: pthread_mutext_init(), pthread_mutex_lock(), pthread_mutex_unlock(),pthread_mutex_destroy()
        - Order: Intialize, Lock, Unlock, Destroy
        - States: Available, Unlocked, Free or Acquired, Locked, Held
        - Meaures: Achieves mutual exclusion, fairness, performance
        - Early Solution: Lock that Disables Interrupts
        - Hardware Support:
            - Test and Set or Atomic Exchange
            - Compare and Swap
            - Load-Linked + Store-Conditional
            - Fetch And Add
        - Issues: Spin-Waiting
            - Solution: Yield, Sleep with Queue
    d. Lock-based Concurrent Data Structures
        - Counters (Sloppy), Linked Lists (Hand Over Hand), Queues, Hash Table
    e. Condition Variables
        - Explicit queu that threads can put themselves on when some state of execution is not as desired Dijkstra's
        - System Calls: pthread_cond_t
        - Operation: wait() = sleep, signal() = wake
        - Producer/Consumer Bounded Buffer Problem
            - Producer threads filling buffer that consumer threads consume, buffer is critical section
            - Mesa and Hoare Semantics - Building condition variable tha will run immediately upon being woken
            - Solution: Use while loops and two conditional variables fill and empty
    f. Sempahores
        - Synchronization Primitive
        - Object with an integer value that we can manipulate with two routines
        - Routings: sem_init(), sem_wait(), sem_post()
        - Binary Sempahores (Locks) - initial value is 1
        - Conditional Variables - initial value is 0
        - Reader-Writer Lock, rwlock_acquire_writelock(), rwlock_release_writelock()
    g. Concurrency Problems
        - Non-Deadlock Bugs
            - Atomicity-Violation
                - The desired serializability among multiple memory accesses is violated (atomicity is not enforced)
            - Order-Violation
                - The desired order between two groups of memory accesses is flipped (order is not enforced)
        - Deadlock Bugs
            - Causes: Dependencies and Encapsulation
            - Conditions
                - Mutual Exclusion
                    - Threads claim exclusive control of resources that they require
                - Hold-and-Wait
                    - Threads hold resources allocated to them while waiting for additional resources
                - No Preemption
                    - Resources cannot be forcibly removed from threads that are holding them
                - Circular Wait
                    - Each thread hohlds one or more resources that are being requested by the next thread in the chain
            - Prevention
                - Circular Wait
                    - Provide a total ordering or partial ordering on lock acquisition
                - Hold and Wait
                    - Acquire all locks at once
                - No Preemption
                    - Try Lock
                - Mutual Exclusion
                    - Wait-Free, use powerful hardware instructions to build data structures that do not require explicit locking
            - Scheduling
                - Know which locks might be grabbed and schedule threads to guarantee no deadlock can occur
            - Detect and Recover
                - Deadlock detector runs periodically and checks for cycles (deadlocks), in the event of deadlock, restart the system
    h. Event Based Concurrency
        - Problems: Concurrency is challenging and developer has little or no control over what is scheduled
        - Event Loop: Wait for event, check what it is, and do required work
        - Event Handler, processes each event
        - API: select(), and poll()
        - Asynchronous I/O
        - Problem State Management: Manual Stack Management
            - Continuation: record the needed information to finish processing this event in some data structure, look up the needed information and process the event
3. Topic #4 - Persistence
    a. I/O Devices
    b. Hard Disk Drives
    c. Redundant Array of Inexpensive Disks
    d. Files and Directories
    e. File System Implementation
    f. Locality and The Fast File System
    g. Crash Consistency
    h. Log-structured File Systems
    i. Date Integrity and Protection
    j. File System Examples
    k. Flash SSD
