Microsoft Certified: Azure Developer Associate

Extract Knowledge and Insights from Your Data with Azure Databricks

    1. Module 1: Introduction to Azure Databricks
        a. Introduction to Databricks
            - Azure Databricks - fully-managed version of the open-source Apache Spark analytics and data processing engine
        b. Create a Databricks Workspace
            - Deploy an Azure Databricks Workspace
                - Create a Resource -> Databricks: Azure Databricks -> Configure
        c. Apache Spark Notebooks
            - ASN - collection of cell that are run to execute code, render formatted text or display graphic visualizations
            - Cluster - networked computers that work together to process your data in notebooks
            - Create a Cluster
                - Databricks -> Launch Workspace -> Clusters -> Create Cluster -> Configure
            - Create A Notebook
                - Databricks -> Create -> Notebook -> Configure
            - Attach and Detach
                - To run notebook you must attach it to a cluster
        d. Exercise - Use Apache Spark Notebooks
            - Notebooks
                - Read and process huge files and data sets
                - Query, explore, and visualize data sets
                - Join disparte data sets found in data lakes
                - Train and evaluate machine learning models
                - Process live streams of data
                - Peform analysis on large graph data sets and social networks
            - Clone Databricks Archive
                - Databricks -> Launch Workspace -> User -> Import 
                - Import URL: https://github.com/MicrosoftDocs/mslearn-azure-databricks-notebooks-fundamentals/blob/master/DBC/01-notebook-fundamentals.dbc?raw=true
    
    2. Module 2: Read and Write Data by Using Azure Databricks
        a. Read and Write Functions
            - Built-In Functions
                - Querying Files - use DataFrames (from resilient distributed datasets) to query large data files
                - Joins and Aggregration
                - Accessing Data - data store in an existing file, upload a file from local system, mount an Azure blob to Databricks
                - Work with Hierarchial Data
                - Data Lakes
                - Azure Data Lake Storage Gen2 - combines Azure Blob Storage and Azure Data Lake Storage Gen1
                - Azure Key Vault Backed Secret Scopes - securely store secrets, such as database-connection strings
        b. Exercise - Read and Write Data By Using Azure Databricks
            - Clone Databricks Archive
                - Databricks -> Launch Workspace -> User -> Import 
                - Import URL: https://github.com/MicrosoftDocs/mslearn-azure-databricks-notebooks-fundamentals/blob/master/DBC/01-notebook-fundamentals.dbc?raw=true
            - Complete Notebooks
                - 01 - 10, Exploratory Data Analysis
    
    3. Module 3: Perform Exploratory Data Analysius with Azure Databricks
        a. Introduciton
            - Exploratory Data Analysis EDA - process of analyzing datasets to find anomalies and missing information
            - Questions to Answer:
                - What type of data is in the dataset and what is its structure?
                - Is there missing or incomplete information?
                - Are there mistakes or anomalies?
                - What are the relationships between different variables?
                - How will different assumptions work against the available dataset?
        b. Exploratory Data Analysis in Azure Databricks
            - Basic EDA - data cleaninsing, handling of missing values, and correlation analysis
                - Import -> Load into Spark DataFrames
            - Advanced EDA
                - Parsimonious Models - shows you the predictive capability of your data by using a minimum number of variables
                - One-Hot Encoding and Feature Scaling - for ML
                - Dimensionality Reduction - transforms data with n dimensions to a represntations of the data in m dimensions, where m is less than n
        c. Exercise - Perform Exploratory Data Analysis with Databricks
            - Clone Databricks Archive
                - Databricks -> Launch Workspace -> User -> Import 
                - Import URL: https://github.com/MicrosoftDocs/mslearn-exploratory-data-analysis/blob/master/DBC/02-exploratory-data-analysis.dbc?raw=true
            - Complete Notebooks
                - 01 - 04
    
    4. Module 4: Train, Evaluate, and Select ML Models with Azure Databricks
        a. Introduction
            - Robust data model - works efficiently, can be used for different kinds of datasets, produces easy to interpret results
        b. Model Training Techniques
            - Train
                - Split the dataset into training and testing
                - Identify the technique - basic regression, classification, or advanced regression techniques
                - Tune the model - achieving optimal performance of your ML model
                    - Select parameteres, train, use model for predictions, correct errors by adjusting parameters
                - Minimize const functions - how far your model is from correctly predicting the relationship between values
                - Evaluate and validate your model
            - Training Techniques
                - Basic Regression - predicst the value of a dependent variable based on its relationship with one or more independent variables
                - Classification - 
                    - Logistic regression - linear regression but dependent variable is either 0 or 1
                    - Support-vector machines - supervised ML models with algorithms used for classification problems
                    - Decision-tree classifier - two-class and multi-class classification problems based on decisions trees, Random Forests, boosted trees, and XDGBoost
                - Advanced Regression
                    - Polynomial regerssion for complex and distributed datasets that can't be captured by using straight-line linear regression techniques
        c. Exercise - Train, Evaluate, and Select a ML Model Using Azure Databricks
            - Clone Databricks Archive
                - Databricks -> Launch Workspace -> User -> Import 
                - Import URL: https://github.com/MicrosoftDocs/mslearn-model-training-selection-evaluation/blob/master/DBC/03-model-training-selection-evaluation.dbc?raw=true
            - Configure Databricks Cluster with Scikit-learn library
            - Complete Notebooks
                - 01 - 04
    
    5. Module 5: Deep Learning with Azure Databricks
        a. Introduction
            - Deep Learning - subset of machine learning that uses algorithms based on the structure and functions of the human brain
                - Advantages - accuracy, scalability, robustness, and adaptability
        b. Deep Learning with Azure Databricks
            - Artificial Neural Networks - simpler representations of the complex and dense neural networks of the human brain
            - Artificial Neuron - mathematical function conceived as a model of a biological neuron
            - Common Use Cases
                - Speech and Image Recognition
                - Health Predictions
                - Security
            - Azure Databricks Deep Learning Solutions
                - Machine Learning Pipelines - open soruce high level deep learning api
                - TensorFlow - high-level numerical computation
                - Distributed Deep Learning - Horovod framework enables complex model training
                - Integrated Libraries - MXNet, Keras, and PyTorch
        c. Exercise - Deep Learning By Using Azure Databricks
            - Clone Databricks Archive
                - Databricks -> Launch Workspace -> User -> Import 
                - Import URL: https://github.com/MicrosoftDocs/mslearn-deep-learning/blob/master/DBC/04-deep-learning.dbc?raw=true
            - Complete Notebooks
                - 01 - 04